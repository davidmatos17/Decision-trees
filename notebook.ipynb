{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree for discretized dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<petallength>\n",
      "\t1.4: Iris-setosa (12)\n",
      "\t1.3: Iris-setosa (7)\n",
      "\t1.5: Iris-setosa (14)\n",
      "\t1.7: Iris-setosa (4)\n",
      "\t1.6: Iris-setosa (7)\n",
      "\t1.1: Iris-setosa (1)\n",
      "\t1.2: Iris-setosa (2)\n",
      "\t1.0: Iris-setosa (1)\n",
      "\t1.9: Iris-setosa (2)\n",
      "\t4.7: Iris-versicolor (5)\n",
      "\t4.5:\n",
      "\t\t<sepallength>\n",
      "\t\t\t6.4: Iris-versicolor (1)\n",
      "\t\t\t5.7: Iris-versicolor (1)\n",
      "\t\t\t5.6: Iris-versicolor (1)\n",
      "\t\t\t6.2: Iris-versicolor (1)\n",
      "\t\t\t6.0: Iris-versicolor (2)\n",
      "\t\t\t5.4: Iris-versicolor (1)\n",
      "\t\t\t4.9: Iris-virginica (1)\n",
      "\t4.9:\n",
      "\t\t<sepalwidth>\n",
      "\t\t\t3.1: Iris-versicolor (1)\n",
      "\t\t\t2.5: Iris-versicolor (1)\n",
      "\t\t\t2.8: Iris-virginica (1)\n",
      "\t\t\t2.7: Iris-virginica (1)\n",
      "\t\t\t3.0: Iris-virginica (1)\n",
      "\t4.0: Iris-versicolor (5)\n",
      "\t4.6: Iris-versicolor (3)\n",
      "\t3.3: Iris-versicolor (2)\n",
      "\t3.9: Iris-versicolor (3)\n",
      "\t3.5: Iris-versicolor (2)\n",
      "\t4.2: Iris-versicolor (4)\n",
      "\t3.6: Iris-versicolor (1)\n",
      "\t4.4: Iris-versicolor (4)\n",
      "\t4.1: Iris-versicolor (3)\n",
      "\t4.8:\n",
      "\t\t<sepallength>\n",
      "\t\t\t5.9: Iris-versicolor (1)\n",
      "\t\t\t6.8: Iris-versicolor (1)\n",
      "\t\t\t6.2: Iris-virginica (1)\n",
      "\t\t\t6.0: Iris-virginica (1)\n",
      "\t4.3: Iris-versicolor (2)\n",
      "\t5.0:\n",
      "\t\t<sepallength>\n",
      "\t\t\t6.7: Iris-versicolor (1)\n",
      "\t\t\t5.7: Iris-virginica (1)\n",
      "\t\t\t6.0: Iris-virginica (1)\n",
      "\t\t\t6.3: Iris-virginica (1)\n",
      "\t3.8: Iris-versicolor (1)\n",
      "\t3.7: Iris-versicolor (1)\n",
      "\t5.1:\n",
      "\t\t<sepallength>\n",
      "\t\t\t6.0: Iris-versicolor (1)\n",
      "\t\t\t5.8: Iris-virginica (3)\n",
      "\t\t\t6.5: Iris-virginica (1)\n",
      "\t\t\t6.3: Iris-virginica (1)\n",
      "\t\t\t6.9: Iris-virginica (1)\n",
      "\t\t\t5.9: Iris-virginica (1)\n",
      "\t3.0: Iris-versicolor (1)\n",
      "\t6.0: Iris-virginica (2)\n",
      "\t5.9: Iris-virginica (2)\n",
      "\t5.6: Iris-virginica (6)\n",
      "\t5.8: Iris-virginica (3)\n",
      "\t6.6: Iris-virginica (1)\n",
      "\t6.3: Iris-virginica (1)\n",
      "\t6.1: Iris-virginica (3)\n",
      "\t5.3: Iris-virginica (2)\n",
      "\t5.5: Iris-virginica (3)\n",
      "\t6.7: Iris-virginica (2)\n",
      "\t6.9: Iris-virginica (1)\n",
      "\t5.7: Iris-virginica (3)\n",
      "\t6.4: Iris-virginica (1)\n",
      "\t5.4: Iris-virginica (2)\n",
      "\t5.2: Iris-virginica (2)\n"
     ]
    }
   ],
   "source": [
    "from Dataset import Dataset\n",
    "from DecisionTree import DecisionTree\n",
    "\n",
    "irisDecisionTree = DecisionTree(Dataset().readCSV('datasets/', 'iris', True)) # Árvore do dataset (iris.csv)\n",
    "irisDecisionTree.DFSPrint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree for discretized dataset (for numerical values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<petalwidth>\n",
      "\t0.10-0.90: Iris-setosa (50)\n",
      "\t0.90-1.70:\n",
      "\t\t<petallength>\n",
      "\t\t\t2.97-4.93: Iris-versicolor (47)\n",
      "\t\t\t4.93-6.90:\n",
      "\t\t\t\t<sepallength>\n",
      "\t\t\t\t\t5.50-6.70:\n",
      "\t\t\t\t\t\t<sepalwidth>\n",
      "\t\t\t\t\t\t\t2.00-2.80: Iris-virginica (3)\n",
      "\t\t\t\t\t6.70-7.90: Iris-virginica (1)\n",
      "\t1.70-2.50:\n",
      "\t\t<sepalwidth>\n",
      "\t\t\t2.80-3.60:\n",
      "\t\t\t\t<petallength>\n",
      "\t\t\t\t\t2.97-4.93:\n",
      "\t\t\t\t\t\t<sepallength>\n",
      "\t\t\t\t\t\t\t5.50-6.70: Iris-virginica (2)\n",
      "\t\t\t\t\t4.93-6.90:\n",
      "\t\t\t\t\t\t<sepallength>\n",
      "\t\t\t\t\t\t\t6.70-7.90: Iris-virginica (15)\n",
      "\t\t\t\t\t\t\t5.50-6.70: Iris-virginica (11)\n",
      "\t\t\t2.00-2.80: Iris-virginica (16)\n",
      "\t\t\t3.60-4.40: Iris-virginica (2)\n"
     ]
    }
   ],
   "source": [
    "from Dataset import Dataset\n",
    "from DecisionTree import DecisionTree\n",
    "\n",
    "irisDecisionTreeBinning = DecisionTree(Dataset().readCSV('datasets/', 'iris', True, True, None, 3), True) # Árvore do dataset (iris.csv) com os valores numéricos discretizados\n",
    "irisDecisionTreeBinning.DFSPrint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GenDataset.py e GenDatasetBig.py** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GenDataset.py** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "game_path = os.path.abspath(os.path.join(os.path.dirname(__file__), 'Game'))\n",
    "sys.path.append(game_path)\n",
    "\n",
    "from Game.searchAlgos.mcts import MCTS\n",
    "from Game.fourGame import FourGame  \n",
    "\n",
    "#função que gera o dataset\n",
    "def gerar_dataset_csv(num_amostras=20000, path='datasets/connect4_dataset.csv', simbolo_ia='X'):\n",
    "    with open(path, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        #headers\n",
    "        header = [f\"cell_{row}_{col}\" for row in range(6) for col in range(7)]\n",
    "        header.append(\"piece_count\")\n",
    "        header.append(\"best_move\")\n",
    "        writer.writerow(header)\n",
    "\n",
    "        exemplos_gerados = 0\n",
    "        tentativas = 0\n",
    "\n",
    "        while exemplos_gerados < num_amostras and tentativas < num_amostras * 10:\n",
    "            tentativas += 1\n",
    "            print(f\"\\n Tentativa #{tentativas}\")\n",
    "\n",
    "            game = FourGame(columns=7, lines=6)\n",
    "            jogadas_totais = random.randint(6, 41)  # mid to late-game\n",
    "\n",
    "            #varia o foco posicional: esquerda, centro, direita ou random extra\n",
    "            pos_focus = random.choice([\"left\", \"center\", \"right\",\"random\"])\n",
    "\n",
    "            jogador = 'O' if simbolo_ia == 'X' else 'X'\n",
    "\n",
    "            for i in range(jogadas_totais - 1):\n",
    "                legal = game.getLegalMoves()\n",
    "                if not legal or game.gameOver():\n",
    "                    break\n",
    "\n",
    "                #filtra jogadas com base no foco posicional\n",
    "                if pos_focus == \"left\":\n",
    "                    legal_focus = [col for col in legal if col <= 2]\n",
    "                elif pos_focus == \"center\":\n",
    "                    legal_focus = [col for col in legal if 2 <= col <= 4]\n",
    "                elif pos_focus == \"right\":\n",
    "                    legal_focus = [col for col in legal if col >= 4]\n",
    "                #jogadas mais random\n",
    "                else:\n",
    "                    legal_focus = [col for col in legal if col <=6]\n",
    "\n",
    "                if not legal_focus:\n",
    "                    legal_focus = legal  \n",
    "\n",
    "                move = random.choice(legal_focus)\n",
    "                game.makeMove(move + 1, jogador)\n",
    "                jogador = 'O' if jogador == 'X' else 'X'\n",
    "\n",
    "            if game.gameOver():\n",
    "                print(\" Jogo terminou antes do MCTS.\")\n",
    "                continue\n",
    "\n",
    "            mcts = MCTS(iaSymbol=simbolo_ia, game=deepcopy(game))\n",
    "            mcts.search(0.5)\n",
    "            best = mcts.bestMove()\n",
    "            if not best:\n",
    "                print(\"MCTS falhou.\")\n",
    "                continue\n",
    "\n",
    "            best_move = best.move\n",
    "            game.makeMove(best_move + 1, simbolo_ia)\n",
    "\n",
    "            # cria entrada no CSV\n",
    "            estado = []\n",
    "            piece_count = 0\n",
    "            for row in game.state:\n",
    "                for cell in row:\n",
    "                    if cell == 'X':\n",
    "                        estado.append(1)\n",
    "                        piece_count += 1\n",
    "                    elif cell == 'O':\n",
    "                        estado.append(2)\n",
    "                        piece_count += 1\n",
    "                    else:\n",
    "                        estado.append(0)\n",
    "\n",
    "            writer.writerow(estado + [piece_count, best_move])\n",
    "            exemplos_gerados += 1\n",
    "            print(f\"Exemplo #{exemplos_gerados} gerado. Foco: {pos_focus}\")\n",
    "\n",
    "    print(f\"\\n{exemplos_gerados} exemplos gerados com sucesso em {path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    gerar_dataset_csv(num_amostras=20000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GenDatasetBig.py**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "game_path = os.path.abspath(os.path.join(os.path.dirname(__file__), 'Game'))\n",
    "sys.path.append(game_path)\n",
    "\n",
    "from Game.searchAlgos.mcts import MCTS\n",
    "from Game.fourGame import FourGame  \n",
    "\n",
    "def gerar_dataset_csv(num_amostras=100000, path='datasets/connect4_dataset.csv', simbolo_ia='X'):\n",
    "    with open(path, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        #headers\n",
    "        header = [f\"cell_{row}_{col}\" for row in range(6) for col in range(7)]\n",
    "        header += [\"piece_count\", \"first_player\", \"current_player\", \"best_move\"]\n",
    "        writer.writerow(header)\n",
    "\n",
    "        exemplos_gerados = 0\n",
    "        tentativas = 0\n",
    "\n",
    "        while exemplos_gerados < num_amostras and tentativas < num_amostras * 10:\n",
    "            tentativas += 1\n",
    "            print(f\"\\nTentativa #{tentativas}\")\n",
    "\n",
    "            game = FourGame(columns=7, lines=6)\n",
    "            jogadas_totais = random.randint(6, 41)  # de mid a late-game\n",
    "\n",
    "            # Escolhe aleatoriamente o primeiro jogador\n",
    "            first_player = random.choice(['X', 'O'])\n",
    "            jogador = first_player if simbolo_ia == 'O' else ('O' if first_player == 'X' else 'X')\n",
    "\n",
    "            # Varia o foco posicional: esquerda, centro, direita, aleatório\n",
    "            pos_focus = random.choice([\"left\", \"center\", \"right\", \"random\"])\n",
    "\n",
    "            for i in range(jogadas_totais - 1):\n",
    "                legal = game.getLegalMoves()\n",
    "                if not legal or game.gameOver():\n",
    "                    break\n",
    "\n",
    "                if pos_focus == \"left\":\n",
    "                    legal_focus = [col for col in legal if col <= 2]\n",
    "                elif pos_focus == \"center\":\n",
    "                    legal_focus = [col for col in legal if 2 <= col <= 4]\n",
    "                elif pos_focus == \"right\":\n",
    "                    legal_focus = [col for col in legal if col >= 4]\n",
    "                else:\n",
    "                    legal_focus = legal\n",
    "\n",
    "                if not legal_focus:\n",
    "                    legal_focus = legal \n",
    "\n",
    "                move = random.choice(legal_focus)\n",
    "                game.makeMove(move + 1, jogador)\n",
    "                jogador = 'O' if jogador == 'X' else 'X'\n",
    "\n",
    "            # Última jogada com MCTS \n",
    "            if game.gameOver():\n",
    "                print(\"Jogo terminou antes do MCTS.\")\n",
    "                continue\n",
    "\n",
    "            mcts = MCTS(iaSymbol=simbolo_ia, game=deepcopy(game))\n",
    "            mcts.search(0.5)\n",
    "            best = mcts.bestMove()\n",
    "            if not best:\n",
    "                print(\"MCTS falhou.\")\n",
    "                continue\n",
    "\n",
    "            best_move = best.move\n",
    "            game.makeMove(best_move + 1, simbolo_ia)\n",
    "            current_player = simbolo_ia\n",
    "\n",
    "            #cria entrada do CSV\n",
    "            estado = []\n",
    "            piece_count = 0\n",
    "            for row in game.state:\n",
    "                for cell in row:\n",
    "                    if cell == 'X':\n",
    "                        estado.append(1)\n",
    "                        piece_count += 1\n",
    "                    elif cell == 'O':\n",
    "                        estado.append(2)\n",
    "                        piece_count += 1\n",
    "                    else:\n",
    "                        estado.append(0)\n",
    "\n",
    "            writer.writerow(estado + [piece_count, first_player, current_player, best_move])\n",
    "            exemplos_gerados += 1\n",
    "            print(f\"Exemplo #{exemplos_gerados} gerado. Foco: {pos_focus}\")\n",
    "\n",
    "    print(f\"\\n{exemplos_gerados} exemplos gerados com sucesso em {path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gerar_dataset_csv(num_amostras=100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os códigos são identicos, a grande diferença são os atributos que contêm, a explicação está em \"Connect4 Dataset\" neste notebook.\n",
    "\n",
    "Resumo:\n",
    "    \n",
    "    1. Escolhe um número aleatório de jogadas de 6 a 41\n",
    "    2. Escolhe quem é o primeiro jogador e alterna entre jogadas\n",
    "    3. Escolhe em que posições do tabuleiro que jogar mais, direita, esquerda , centro ou totalmente aleatório\n",
    "    4. Faz jogadas com tudo em mente\n",
    "    5. Na última jogada faz com o MCTS e obtêm-se o melhor move para o estado representado pelas células "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Estruturas de Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Node**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "\n",
    "    def __init__(self, attribute, value, label, isClass = False, counter = None):\n",
    "        self.attribute = attribute\n",
    "        self.isClass = isClass\n",
    "        self.label = label\n",
    "        self.value = value\n",
    "        if (not isClass):\n",
    "            self.neighbours = []\n",
    "        else:\n",
    "            self.counter = counter\n",
    "\n",
    "    def addNeighbour(self, neighbour):\n",
    "        self.neighbours.append(neighbour)\n",
    "    \n",
    "    def getNeighbours(self):\n",
    "        return self.neighbours\n",
    "        \n",
    "    def getAttribute(self):\n",
    "        return self.attribute\n",
    "\n",
    "    def getValue(self):\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construtor da classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, attribute, value, label, isClass = False, counter = None):\n",
    "    self.attribute = attribute\n",
    "    self.isClass = isClass\n",
    "    self.label = label\n",
    "    self.value = value\n",
    "    if (not isClass):\n",
    "        self.neighbours = []\n",
    "    else:\n",
    "        self.counter = counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos:\n",
    "\n",
    "- 'attribute': Representa o atributo pelo qual o nó é dividido. Se 'isClass' for 'True', este representa a classe final do nó.\n",
    "\n",
    "- 'value': Representa o valor do nó.\n",
    "\n",
    "- 'isClass': (Opcional, por omissão é False) Um valor booleano que nos indica se o nó representa uma classe final (folha).\n",
    "\n",
    "- 'label': Nome do atributo em questão.\n",
    "\n",
    "- 'neighbours' - Inicializa uma lista vazia para guardar os vizinhos (filhos) do nó, caso não seja um nó classe (folha).\n",
    "\n",
    "- 'counter' - Número de exemplos do dataset que levam ao valor indicado pelo nó caso seja classe<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métodos\n",
    "\n",
    "Todos os métodos desta estrutura de dados são apenas getters da informação já anteriormente apresentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbours(self):\n",
    "        return self.neighbours\n",
    "        \n",
    "def getAttribute(self):\n",
    "    return self.attribute\n",
    "\n",
    "def getValue(self):\n",
    "    return self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, existe uma exceção no método 'addNeighbour':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNeighbour(self, neighbour):\n",
    "        self.neighbours.append(neighbour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método permite-nos de facto fazer alterações no nó. Com o mesmo podemos adicionar nós vizinhos à lista criada no dado nó.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DataSet**\n",
    "\n",
    "A classe seguinte, permite-nos manipular os dados do dataset como uma matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv                                                                              \n",
    "import copy                                                                             \n",
    "\n",
    "class Dataset():\n",
    "\n",
    "    def __init__(self, dataset=None, header=None):                                      \n",
    "        if (dataset != None) and (header != None):                                      \n",
    "            self.array = dataset                                                        \n",
    "            self.header = header                                                        \n",
    "            self.lines = len(self.array)                                                \n",
    "            self.cols = len(self.array[0])                                              \n",
    "    \n",
    "    def readCSV(self, path, filename, hasId=False, hasHeader=True, headerInput=None):   \n",
    "        csvFile = open(path + filename + '.csv', 'r')                                   \n",
    "        reader = csv.reader(csvFile)                                                    \n",
    "\n",
    "        if hasHeader:                                                                   \n",
    "            self.header = next(reader)                                                  \n",
    "            self.header.pop(0)                                                          \n",
    "        else:\n",
    "            self.header = headerInput                                                   \n",
    "\n",
    "        self.array = []                                                                 \n",
    "        for row in reader:                                                              \n",
    "            self.array.append(row)                                                      \n",
    "\n",
    "        if hasId:                                                                       \n",
    "            for i in range(len(self.array)):                                            \n",
    "                self.array[i].pop(0)                                                    \n",
    "\n",
    "        self.lines = len(self.array)                                                    \n",
    "        self.cols = len(self.array[0])                                                  \n",
    "        return self                                                                     \n",
    "    \n",
    "    def getValue(self, line, col):                                                      \n",
    "        return self.array[line][col]\n",
    "\n",
    "    def copy(self):                                                                     \n",
    "        return Dataset(copy.deepcopy(self.array), copy.deepcopy(self.header))\n",
    "    \n",
    "    def removeLine(self, line):                                                         \n",
    "        self.array.pop(line)                                                            \n",
    "        self.lines -= 1                                                                \n",
    "\n",
    "    def removeColumn(self, col):                                                        \n",
    "        if self.header: self.header.pop(col)                                            \n",
    "        for i in range(len(self.array)):                                                \n",
    "            self.array[i].pop(col)                                                     \n",
    "        self.cols -= 1                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Construtor da classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, dataset = None, header = None):                                  # Inicializa a classe Dataset com dataset e header opcionais\n",
    "    if ((dataset != None) and (header != None)):                                    # Verifica se dataset e header não são None\n",
    "        self.array = dataset                                                        # Atribui dataset ao atributo array da instância\n",
    "        self.header = header                                                        # Atribui header ao atributo header da instância\n",
    "        self.lines = len(self.array)                                                # Calcula e armazena o número de linhas do dataset\n",
    "        self.cols = len(self.array[0])                                              # Calcula e armazena o número de colunas do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Atributos:**\n",
    "- 'self.array': Armazena os dados do dataset. \n",
    "\n",
    "- 'self.header': Armazena os nomes das colunas.\n",
    "\n",
    "- 'self.lines': Armazena o número de linhas no dataset.\n",
    "\n",
    "- 'self.cols': Armazena o número de colunas no dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Métodos**\n",
    "\n",
    "O método 'readCSV':\n",
    "- Lê um arquivo CSV e carrega os seus dados para a instância do Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(self, path, filename, hasId=False, hasHeader=True, headerInput = None, binCount = None): # Lê um arquivo CSV e carrega os dados no dataset\n",
    "        csvFile = open(path+filename+'.csv', 'r')                                   # Abre o arquivo CSV no modo de leitura\n",
    "        reader = csv.reader(csvFile)                                                # Cria um objeto reader para iterar sobre as linhas do CSV\n",
    "\n",
    "        if (hasHeader == True):                                                     # Se o arquivo CSV tem um cabeçalho\n",
    "            self.header = next(reader)                                              # Lê a primeira linha como cabeçalho\n",
    "            self.header.pop(0)                                                      # Remove o primeiro elemento do cabeçalho (presumivelmente um ID)\n",
    "        else:\n",
    "            self.header = headerInput                                               # Se não houver cabeçalho, usa o headerInput fornecido\n",
    "\n",
    "        self.array = []                                                             # Inicializa o array para armazenar os dados\n",
    "        for row in reader:                                                          # Itera sobre as linhas restantes do CSV\n",
    "            self.array.append(row)                                                  # Adiciona cada linha ao array\n",
    "\n",
    "        if (hasId):                                                                 # Se as linhas têm um ID\n",
    "            for i in range(len(self.array)):                                        # Itera sobre todas as linhas\n",
    "                self.array[i].pop(0)                                                # Remove o primeiro elemento de cada linha (presumivelmente um ID)\n",
    "\n",
    "        self.lines = len(self.array)                                                # Calcula e armazena o número de linhas do array\n",
    "        self.cols = len(self.array[0])                                              # Calcula e armazena o número de colunas do array\n",
    "\n",
    "        if (binCount != None):                                                      # Se binCount não for None                \n",
    "            self.binning(binCount)                                                  # Chama a função binning com o valor de binCount\n",
    "            \n",
    "        return self                                                                 # Retorna a instância do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método 'getValue':\n",
    "- Retorna o valor armazenado numa célula específica do dataset, identificada pelos índices da linha e coluna fornecidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValue(self, line, col):                                                      # Retorna o valor na linha e coluna especificadas\n",
    "        return self.array[line][col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método 'copy':\n",
    "- Este método retorna uma cópia profunda da instância do Dataset, garantindo que alterações na cópia não afetem o original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy(self):                                                                     # Retorna uma cópia profunda do dataset\n",
    "        return Dataset(copy.deepcopy(self.array), copy.deepcopy(self.header))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método 'removeLine':\n",
    "- Este método remove uma linha específica do dataset, identificada pelo índice fornecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLine(self, line):                                                         # Remove a linha especificada do dataset\n",
    "        self.array.pop(line)                                                        # Remove a linha do array\n",
    "        self.lines -= 1                                                             # Decrementa o contador de linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método 'removeColumn':\n",
    "- Este método remove uma coluna específica do dataset, identificada pelo índice fornecido. Se existir um cabeçalho, ele também é atualizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeColumn(self, col):                                                        # Remove a coluna especificada do dataset\n",
    "        if (self.header): self.header.pop(col)                                      # Se houver um cabeçalho, remove a coluna correspondente\n",
    "        for i in range(len(self.array)):                                            # Itera sobre todas as linhas do array\n",
    "            self.array[i].pop(col)                                                  # Remove a coluna de cada linha\n",
    "        self.cols -= 1                                                              # Decrementa o contador de colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método 'binning':\n",
    "- Este método junta os valores númericos em \"bin\" (intervalos), diminuindo o tamanha do dataset mas levando a uma pequena perda de informação em alguns casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning(self, binCount):                                                        # Bins continuous data into discrete intervals.\n",
    "    for col in range(self.cols - 1):                                                # Assuming last column is the target\n",
    "        try:                                                                        # Check if column is numeric\n",
    "            colData = [float(self.array[i][col]) for i in range(self.lines)]        # Convert column data to float\n",
    "        except ValueError:                                                          # If column is not numeric, skip\n",
    "            continue                                                                \n",
    "\n",
    "        minVal, maxVal = min(colData), max(colData)                                 # Get min and max values of column\n",
    "        binWidth = (maxVal - minVal) / binCount                                     # Calculate bin width\n",
    "        bins = [minVal + i * binWidth for i in range(binCount + 1)]                 # Create bins\n",
    "\n",
    "        for i in range(self.lines):                                                 # Iterate through rows\n",
    "            value = float(self.array[i][col])                                       # Get value of cell\n",
    "            for b in range(len(bins) - 1):                                          # Iterate through bins\n",
    "                if (bins[b] <= value < bins[b + 1]):                                # Check if value is within bin\n",
    "                    self.array[i][col] = f\"{bins[b]:.2f}-{bins[b + 1]:.2f}\"         # Replace value with bin range\n",
    "                    break                                                           # Exit loop\n",
    "                else:                                                               # If value is not within bin\n",
    "                    self.array[i][col] = f\"{bins[-2]:.2f}-{bins[-1]:.2f}\"           # Replace value with last bin range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Decision Tree Learning Algorithm: ID3**\n",
    "\n",
    "O seguinte código define uma classe 'ID3', para a construção de uma árvore de decisão usando o algoritmo ID3. Este algoritmo é um método fundamental na classificação de dados e para a tomada de decisões. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ID3():  \n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.dataSetEntropy = self.__calcDatasetEntorpy()\n",
    "        self.bestAtributte = self.__getBestGainAtributte()\n",
    "\n",
    "    # Função de cálculo da entropia de determinado array com valores das classes \n",
    "    def __Entropy(self, X):\n",
    "        sum = 0\n",
    "        for i in X:\n",
    "            if (X[i] == 1.0): return 0\n",
    "            sum += -(X[i]) * np.log2(X[i])\n",
    "        return sum\n",
    "    \n",
    "    # Função de cálculo da entropia do dataset\n",
    "    def __calcDatasetEntorpy(self):\n",
    "        values = {}\n",
    "        for line in range(0, self.dataset.lines):\n",
    "            value = self.dataset.getValue(line, self.dataset.cols-1)\n",
    "            if (not (value in values)):\n",
    "                values[value] = 1\n",
    "            else:\n",
    "                values[value] += 1\n",
    "\n",
    "        for key in values:\n",
    "            values[key] /= self.dataset.lines\n",
    "\n",
    "        return self.__Entropy(values)\n",
    "    \n",
    "    # Função de decisão e escolha do melhor atributo do dataset apresentado\n",
    "    def __getBestGainAtributte(self):\n",
    "        maxGain = float('-inf')\n",
    "        colMax = 0\n",
    "        valuesMax = {}\n",
    "        for j in range(0, self.dataset.cols-1):\n",
    "            values = {}\n",
    "            gain = self.dataSetEntropy\n",
    "            for i in range(0, self.dataset.lines):\n",
    "                value = self.dataset.getValue(i, j)\n",
    "\n",
    "                if (not (value in values)):\n",
    "                    values[value] = {\"total\": 0}\n",
    "                \n",
    "                classVar = self.dataset.getValue(i, self.dataset.cols-1)\n",
    "\n",
    "                if (not (classVar in values[value])):\n",
    "                    values[value][classVar] = 1\n",
    "                else:\n",
    "                    values[value][classVar] += 1\n",
    "                \n",
    "                values[value][\"total\"] += 1\n",
    "\n",
    "            for key in values:\n",
    "                for key2 in values[key]:\n",
    "                    if key2 != \"total\":\n",
    "                        values[key][key2] /= values[key][\"total\"]\n",
    "                total = values[key].pop(\"total\")\n",
    "                gain -= (total/self.dataset.lines) * self.__Entropy(values[key])\n",
    "                values[key][\"total\"] = total\n",
    "\n",
    "            if (gain > maxGain):\n",
    "                maxGain = gain\n",
    "                colMax = j\n",
    "                valuesMax = values\n",
    "\n",
    "        return colMax, valuesMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida, iremos apresentar detalhadamente a classe e os métodos.<br/><br/>\n",
    "\n",
    "### **Classe: 'ID3'**\n",
    "\n",
    "A classe 'ID3' contém métodos para calcular a entropia de um dado conjunto de dados (dataset), determinar o melhor atributo para separar os dados, e inicializar a construção da árvore de decisão.<br/><br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Construtor da classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, dataset):\n",
    "    self.dataset = dataset\n",
    "    self.dataSetEntropy = self.__calcDatasetEntropy()\n",
    "    self.bestAtributte = self.__getBestGainAttribute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos:\n",
    "\n",
    "- 'dataset' - Guarda o dataset fornecido (Instância da classe Dataset).\n",
    "\n",
    "- 'dataSetEntropy' - Guarda a entropia de todo o dataset, calculado pelo método '__calcDatasetEntropy'.\n",
    "\n",
    "- 'bestAttribute' - Guarda o melhor atributo do dataset (ou seja o atributo ganho máximo), calculado por '__getBestGainAttribute'.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Entropia**\n",
    "\n",
    "Este método calcula a entropia do dataset, que mede a incerteza do mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __Entropy(self, X):\n",
    "    sum = 0                                                                     # Inicializamos a soma com 0\n",
    "    for i in X:                                                                 # Para cada elemento do dicionário X\n",
    "        if (X[i] == 1.0): return 0                                              # Se o valor do elemento for 1, a entropia é 0\n",
    "        sum += -(X[i]) * np.log2(X[i])                                          # Caso contrário, a soma fica com o simétrico do valor do elemento multiplicado pelo logaritmo de base 2 do valor do mesmo\n",
    "    return sum                                                                  # Retornamos a soma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Parâmetros:\n",
    "\n",
    "- 'X' - Um dicionário que representa a distribuição de frequência das classes.<br/><br/>\n",
    "\n",
    "Retorno:\n",
    "\n",
    "- Retorna a entropia do dataset.<br/><br/>\n",
    "\n",
    "**Cálculo da entropia:**\n",
    "\n",
    "A entropia é calculada segundo a seguinte fórmula:<br/><br/>\n",
    "\n",
    "$$H(X) = -\\sum p(x) \\log_2 p(x)$$\n",
    "\n",
    "Onde p(x) é a probabilidade da classe x.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Cálculo da Entropia**\n",
    "\n",
    "Este método calcula a entropia do dataset inteiro, primeiro determinando a distribuição de frequência das classes e depois aplicando a fórmula de cálculo da entropia (conforme apresentada anteriormente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __calcDatasetEntropy(self):\n",
    "    values = {}                                                                 # Dicionário para guardar a contagem de ocorrencias de cada classe\n",
    "    for line in range(0, self.dataset.lines):                                   # Para cada linha do dataset                \n",
    "        value = self.dataset.getValue(line, self.dataset.cols - 1)              # Obtemos o valor da classe\n",
    "        if (not (value in values)):\n",
    "            values[value] = 1                                                   # Se o valor ainda não estiver no dicionário, inicialziamos com o valor 1\n",
    "        else:\n",
    "            values[value] += 1                                                  # Caso já esteja no dicionário, incrementamos o valor em 1\n",
    "\n",
    "    for key in values:                                                          # Para cada par chave-valor no dicionário                                           \n",
    "        values[key] /= self.dataset.lines                                       # Calculamos a probabilidade de cada classe dividindo o número de ocorrencias pelo número total de linhas\n",
    "\n",
    "    return self.__Entropy(values)                                               # Calculamos a entropia do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumo:\n",
    "\n",
    "1. É criado um dicionário 'values' vazio, onde iremos guardar a contagem de ocorrências de cada classe.\n",
    "\n",
    "2. Percorremos cada linha do conjunto de dados, obtemos o valor de cada classe e atualizamos o dicionário 'values' para contar quantas vezes cada classe aparece no dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retorno:\n",
    "\n",
    "- Retorna a entropia do dataset, invocando o método '__Entropy' apresentado anteriomente.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Obter o atributo com maior ganho**\n",
    "\n",
    "Este método determina qual o atributo (coluna) do dataset proporciona o maior ganho de informação. Este ganho é usado para decidir qual atributo usar para dividir os dados em cada nó da árvore de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getBestGainAttribute(self):\n",
    "    maxGain = float('-inf')                                                     # Inicializamos o ganho máximo com o menor valor possível, para garantir que qualquer ganho seja maior\n",
    "    colMax = 0                                                                  # Inicializamos colmax a 0, que representa o índice da coluna com o maior ganho                         \n",
    "    valuesMax = {}                                                              # Inicializamos valuesMax como um dicionário vazio, que guardará os valores de cada atributo da coluna com o maior ganho\n",
    "    for j in range(0, self.dataset.colls - 1):                                  # Para cada coluna do dataset, exceto a última (que contém as classes)\n",
    "        values = {}                                                             # Inicializamos um dicionário vazio para guardar os valores de cada valor do atributo\n",
    "        gain = self.dataSetEntropy                                              # Inicializamos o ganho com a entropia do dataset\n",
    "        for i in range(0, self.dataset.lines):                                  # Para cada linha do dataset\n",
    "            value = self.dataset.getValue(i, j)                                 # Obtemos o valor do atributo na coluna j\n",
    "\n",
    "            if (not (value in values)):                                         # Se o valor ainda não estiver no dicionário de valores                                  \n",
    "                values[value] = {\"total\": 0}                                    # Inicializamos o valor no dicionário com um dicionário vazio, que guardará a contagem de cada classe\n",
    "\n",
    "            classVar = self.dataset.getValue(i, self.dataset.colls - 1)         # Obtemos o valor da classe\n",
    "\n",
    "            if (not (classVar in values[value])):                               # Se a classe ainda não estiver no dicionário do valor do atributo\n",
    "                values[value][classVar] = 1                                     # Inicializamos a classe no dicionário do valor value com o valor 1\n",
    "            else:                                                               # Caso contrário\n",
    "                values[value][classVar] += 1                                    # Incrementamos o valor da classe no dicionário do valor value\n",
    "\n",
    "            values[value][\"total\"] += 1                                         # Incrementamos o total de valores do atributo\n",
    "\n",
    "        for key in values:                                                      # Para cada chave no dicionário de valores                            \n",
    "            for key2 in values[key]:                                            # Para cada chave no dicionário de valores do atributo                      \n",
    "                if key2 != \"total\":                                             # Se a chave não for \"total\"                            \n",
    "                    values[key][key2] /= values[key][\"total\"]                   # Calculamos a probabilidade de cada classe dividindo o número de ocorrências pelo número total de valores do atributo\n",
    "            total = values[key].pop(\"total\")                                    # Removemos o total do dicionário de valores do atributo\n",
    "            gain -= (total / self.dataset.lines) * self.__Entropy(values[key])  # Calculamos o ganho subtraindo a entropia do atributo multiplicada pela probabilidade do atributo\n",
    "            values[key][\"total\"] = total                                        # Recuperamos o total do dicionário de valores do atributo\n",
    "\n",
    "        if (gain > maxGain):                                                    # Se o ganho for maior que o ganho máximo\n",
    "            maxGain = gain                                                      # Atualizamos o ganho máximo\n",
    "            colMax = j                                                          # Atualizamos o índice da coluna com o maior ganho\n",
    "            valuesMax = values                                                  # Atualizamos os valores do atributo da coluna com o maior ganho\n",
    "\n",
    "    return colMax, valuesMax                                                    # Retornamos o índice da coluna com o maior ganho e os valores de cada atributo da coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumo:\n",
    "\n",
    "1. Iteramos sobre cada atributo (coluna) do dataset.\n",
    "\n",
    "2. Contamos as ocorrências de cada par (valor do atributo classe) e o total de linhas de cada valor do atributo (para calculo da probabilidade).\n",
    "\n",
    "3. Calculamos o ganho de informação para o atributo.\n",
    "\n",
    "4. Atualizamos o maior ganho e a melhor coluna, se necessário.\n",
    "\n",
    "Retorno:\n",
    "\n",
    "- Retorna um tuplo '(colMax, valuesMax)', onde o colMax representa o index do atributo (coluna) com o maior ganho de informação e valuesMax que são os diferentes valores do atributo e as suas frequências.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Árvore de Decisão**\n",
    "\n",
    "Já definidos o ID3 e a estrutura de dados Node, podemos por fim definir a Árvore de Decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ID3 import ID3\n",
    "from Node import Node\n",
    "from Dataset import Dataset\n",
    "import copy\n",
    "\n",
    "class DecisionTree():\n",
    "\n",
    "    def __init__(self, dataset, binning = False):\n",
    "        self.initialDataset = dataset\n",
    "        self.root = self.__generateNode(dataset)\n",
    "        self.binning = binning\n",
    "\n",
    "    def __generateNode(self, dataset, tabI=0, numRemovedColumns=0, value=None):\n",
    "        attribute, values = ID3(dataset).bestAtributte\n",
    "        node = Node(attribute, value, dataset.header[attribute])\n",
    "\n",
    "        for key in values:\n",
    "            isClass = False\n",
    "            maxValue = float('-inf')\n",
    "            maxkey = 'failed'\n",
    "            maxkey2 = 'failed'\n",
    "            for key2 in values[key]:\n",
    "                if (key2 != \"total\"):\n",
    "                    if (values[key][key2] == 1.0):\n",
    "                        node.addNeighbour(Node(key2, key, None, True, values[key][\"total\"]))\n",
    "                        isClass = True\n",
    "                        break\n",
    "                    elif (len(dataset.header) == 2):\n",
    "                        if maxValue < values[key][key2] and key2 != \"total\":\n",
    "                            maxValue = values[key][key2]\n",
    "                            maxkey = key\n",
    "                            maxkey2 = key2\n",
    "\n",
    "            if (not isClass):\n",
    "                if (len(dataset.header) == 2):\n",
    "                    node.addNeighbour(Node(maxkey2, maxkey, None, True, int(values[maxkey][\"total\"]*values[maxkey][maxkey2])))\n",
    "                else:\n",
    "                    \n",
    "                    datasetCopy = dataset.copy()\n",
    "                    linestoRemove = []\n",
    "                    for i in range(len(datasetCopy.array)):\n",
    "                        if (datasetCopy.array[i][attribute] != key):\n",
    "                            linestoRemove.append(i)\n",
    "\n",
    "                    for x in sorted(linestoRemove, reverse=True):\n",
    "                        datasetCopy.removeLine(x)\n",
    "\n",
    "                    datasetCopy.removeColumn(attribute)\n",
    "\n",
    "                    node.addNeighbour(self.__generateNode(datasetCopy, tabI+2, numRemovedColumns+1, key))\n",
    "\n",
    "        return node\n",
    "\n",
    "    def DFSPrint(self, tabI = 0, node = None):\n",
    "        \n",
    "        if (node == None):\n",
    "            node = self.root\n",
    "        \n",
    "        print('\\t'*tabI + '<'+node.label+'>')\n",
    "        \n",
    "        for currentNode in node.getNeighbours():\n",
    "\n",
    "            if (currentNode.isClass):\n",
    "                print(('\\t'*(tabI+1))+currentNode.getValue()+': ' + currentNode.getAttribute() + ' (' + str(currentNode.counter) + ')')\n",
    "\n",
    "            else:\n",
    "                print(('\\t'*(tabI+1))+currentNode.getValue()+':')\n",
    "                self.DFSPrint(tabI+2, currentNode)\n",
    "\n",
    "    def classifyMultipleExamples(self, path, file):\n",
    "\n",
    "        dataset = Dataset().readCSV(path, file, True, False)\n",
    "        for line in range(dataset.lines):\n",
    "            classExmp = self.classifyExample(copy.deepcopy(dataset), line)\n",
    "            if (classExmp == -1):\n",
    "                print('Not Found!!')\n",
    "            else:\n",
    "                print('Line ' + str(line+1) + ' Class: ' + classExmp)\n",
    "        return\n",
    "    \n",
    "    def classifyExample(self, dataset, line):\n",
    "\n",
    "        actualNode = self.root\n",
    "        value = dataset.array[line][actualNode.getAttribute()]\n",
    "\n",
    "        while (actualNode.isClass != True):\n",
    "            \n",
    "            neighbours = actualNode.getNeighbours()\n",
    "            \n",
    "            found = False\n",
    "            for node in (neighbours):\n",
    "                if (self.binning == False):\n",
    "                    if node.getValue() == value:\n",
    "                        dataset.removeColumn(actualNode.getAttribute())\n",
    "                        actualNode = node\n",
    "                        if (actualNode.isClass != True): value = dataset.array[line][(actualNode.getAttribute())]\n",
    "                        found = True\n",
    "                        break\n",
    "                else:\n",
    "                    spliting = node.getValue().split('-')\n",
    "                    if (spliting[0].replace(\".\", \"\", 1).isdigit() == True):\n",
    "                        minVal = float(spliting[0])\n",
    "                        maxVal = float(spliting[1])\n",
    "                        value = float(value)\n",
    "                        if value >= minVal and value <= maxVal:\n",
    "                            dataset.removeColumn(actualNode.getAttribute())\n",
    "                            actualNode = node\n",
    "                            if (actualNode.isClass != True): value = dataset.array[line][(actualNode.getAttribute())]\n",
    "                            found = True\n",
    "                            break\n",
    "                    else:\n",
    "                        if node.getValue() == value:\n",
    "                            dataset.removeColumn(actualNode.getAttribute())\n",
    "                            actualNode = node\n",
    "                            if (actualNode.isClass != True): value = dataset.array[line][(actualNode.getAttribute())]\n",
    "                            found = True\n",
    "                            break\n",
    "\n",
    "            if (found == False): return -1\n",
    "    \n",
    "        return actualNode.getAttribute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Construtor da classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, dataset, binning = False):\n",
    "        self.initialDataset = dataset\n",
    "        self.root = self.__generateNode(dataset)\n",
    "        self.binning = binning                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos:\n",
    "\n",
    "- 'initialDataset' - Guarda o dataset original (Instância da classe Dataset).\n",
    "- 'root' - Armazena o nó raiz da árvore, gerado pela função '__generateNode'.\n",
    "- 'binning' - Boolean que representa se foi ou não realizado binning nos valores numéricos (discretizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Método: Criar nós\n",
    "\n",
    "O método faz uma construção recursiva da árvre de decisão, criando nós para os melhores atributos e nós filhos para os respetivos valores. Isto acontece até que todos os dados sejam classificados como folhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __generateNode(self, dataset, tabI=0, value=None):                          # Função recursiva para gerar os nós da árvore    \n",
    "    attribute, values = ID3(dataset).bestAtributte                              # Obtemos o atributo com o maior ganho e seus valores\n",
    "    node = Node(attribute, value)                                               # Criamos um nó com o atributo e o valor\n",
    "    for key in values:                                                          # Para cada valor do atributo com o maior ganho\n",
    "        isClass = False \n",
    "        maxValue = float('-inf')\n",
    "        maxkey = 'failed'\n",
    "        maxkey2 = 'failed'                                                        # Inicializamos a variável isClass como False\n",
    "        for key2 in values[key]:                                                # Para cada chave no dicionário de valores do atributo\n",
    "            if (key2 != \"total\"):                                               # Se a chave não for \"total\"\n",
    "                if (values[key][key2] == 1.0):                                  # Se o valor da chave for 1\n",
    "                    node.addNeighbour(Node(key2, key, True))                    # Adicionamos um nó com o valor da chave e o valor do atributo como True\n",
    "                    isClass = True                                              # Atualizamos a variável isClass para True\n",
    "                    break\n",
    "                elif (len(dataset.header) == 2):                                # No caso dos valores terem sofrido binning existe uma pequena chance\n",
    "                    if maxValue < values[key][key2] and key2 != \"total\":        # de o mesmo intrevalo ter duas classes então será escolhida a   \n",
    "                        maxValue = values[key][key2]                            # de maior frequência\n",
    "                        maxkey = key\n",
    "                        maxkey2 = key2                                                    \n",
    "        if (not isClass):\n",
    "            if (len(dataset.header) == 2):\n",
    "                node.addNeighbour(Node(maxkey2, maxkey, None, True, int(values[maxkey][\"total\"]*values[maxkey][maxkey2])))  # Se isClass for False  \n",
    "            else:\n",
    "                datasetCopy = dataset.copy()                                        # Copiamos o dataset\n",
    "                linestoRemove = []                                                  # Inicializamos uma lista vazia para guardar as linhas a serem removidas\n",
    "                for i in range(len(datasetCopy.array)):                             # Para cada linha do dataset\n",
    "                    if (datasetCopy.array[i][attribute] != key):                    # Se o valor do atributo for diferente do valor do atributo com o maior ganho\n",
    "                        linestoRemove.append(i)                                     # Adicionamos o índice da linha à lista de linhas a serem removidas\n",
    "\n",
    "                for x in sorted(linestoRemove, reverse=True):                       # Para cada índice de linha na lista de linhas a serem removidas\n",
    "                    datasetCopy.removeLine(x)                                       # Removemos a linha do dataset\n",
    "\n",
    "                datasetCopy.removeCollum(attribute)                                 # Removemos a coluna do dataset\n",
    "\n",
    "                node.addNeighbour(self.__generateNode(datasetCopy, tabI+2, key))    # Adicionamos um nó filho gerado recursivamente com o dataset cortado\n",
    "\n",
    "    return node                                                                     # Retornamos o nó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumo:\n",
    "\n",
    "1. Identificamos o melhor atributo para dividir os dados usando o algoritmo ID3.\n",
    "\n",
    "2. Criamos um nó com esse atributo como raiz da subárvore.\n",
    "\n",
    "3. Para cada valor do atributo, geramos nós filhos/folhas.\n",
    "\n",
    "4. Os nós filhos representam ramificações da árvore com base nos próximos melhores atributos.<br/><br/>\n",
    "\n",
    "Retorno:\n",
    "\n",
    "- Retorna o nó raiz da árvore de decisão, que inclui recursivamente nós filhos para cada valor do melhor atributo identificado no dataset.<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método: Imprimir segundo um DFS**\n",
    "\n",
    "O método imprime hierarquicamente a árvore de decisão, aplicando uma pesquisa em profundidade (DFS) na mesma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def DFSPrint(self, tabI=0, node=None):                                                             # Função para imprimir a árvore em profundidade\n",
    "    \n",
    "    if node is None:                                                                               # Função para imprimir a árvore em profundidade\n",
    "        node = self.root                                                                           # O nó é a raiz da árvore\n",
    "\n",
    "    print('\\t' * tabI + '<' + str(node.label) + '>')                                               # Imprimimos o nome do atributo do nó\n",
    "    \n",
    "    for currentNode in node.getNeighbours():                                                        # Para cada nó vizinho do nó passado como parâmetro\n",
    "        if currentNode.isClass:                                                                     # Se o nó for uma classe\n",
    "            print('\\t' * (tabI + 1) + str(currentNode.getValue()) + ': ' +                          # Imprimimos o valor do nó\n",
    "                str(currentNode.getAttribute()) + ' (' + str(currentNode.counter) + ')')                \n",
    "        else:                                                                                       # Caso contrário\n",
    "            print('\\t' * (tabI + 1) + str(currentNode.getValue()) + ':')                            # Imprimimos o valor do nó\n",
    "            self.DFSPrint(tabI + 2, currentNode)                                                    # Chamamos a função recursivamente para imprimir os nós filhos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Facilita a compreensão da estrutura da árvore de decisão.\n",
    "\n",
    "- Permite uma visualização clara dos atributos e valores em cada nível da árvore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Interface**\n",
    "main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Choose one tree: \n",
      " [1] Weather Tenis Tree \n",
      " [2] Weather Tenis Tree with Bining \n",
      " [3] Restaurant Stay Tree \n",
      " [4] Iris Tree \n",
      " [5] Iris Tree with Bining \n",
      " [6] Connect Four Tree (Can't be read or its hard to read)\n",
      "\n",
      "Tree: \n",
      "\n",
      "<Weather>\n",
      "\tsunny:\n",
      "\t\t<Humidity>\n",
      "\t\t\t75.33-85.67: no (1)\n",
      "\t\t\t85.67-96.00: no (2)\n",
      "\t\t\t65.00-75.33: yes (2)\n",
      "\tovercast: yes (4)\n",
      "\trainy:\n",
      "\t\t<Windy>\n",
      "\t\t\tFALSE: yes (3)\n",
      "\t\t\tTRUE: no (2)\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Choose one tree: \n",
      " [1] Weather Tenis Tree \n",
      " [2] Weather Tenis Tree with Bining \n",
      " [3] Restaurant Stay Tree \n",
      " [4] Iris Tree \n",
      " [5] Iris Tree with Bining \n",
      " [6] Connect Four Tree (Can't be read or its hard to read)\n",
      "\n",
      "Tree: \n",
      "\n",
      "<Weather>\n",
      "\tsunny:\n",
      "\t\t<Humidity>\n",
      "\t\t\t75.33-85.67: no (1)\n",
      "\t\t\t85.67-96.00: no (2)\n",
      "\t\t\t65.00-75.33: yes (2)\n",
      "\tovercast: yes (4)\n",
      "\trainy:\n",
      "\t\t<Windy>\n",
      "\t\t\tFALSE: yes (3)\n",
      "\t\t\tTRUE: no (2)\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Choose one tree: \n",
      " [1] Weather Tenis Tree \n",
      " [2] Weather Tenis Tree with Bining \n",
      " [3] Restaurant Stay Tree \n",
      " [4] Iris Tree \n",
      " [5] Iris Tree with Bining \n",
      " [6] Connect Four Tree (Can't be read or its hard to read)\n",
      "\n",
      "Tree: \n",
      "\n",
      "<Weather>\n",
      "\tsunny:\n",
      "\t\t<Humidity>\n",
      "\t\t\t75.33-85.67: no (1)\n",
      "\t\t\t85.67-96.00: no (2)\n",
      "\t\t\t65.00-75.33: yes (2)\n",
      "\tovercast: yes (4)\n",
      "\trainy:\n",
      "\t\t<Windy>\n",
      "\t\t\tFALSE: yes (3)\n",
      "\t\t\tTRUE: no (2)\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n",
      "Invalid Input!\n",
      "\n",
      "Decision Trees using ID3 Algorithm!\n",
      "\n",
      "Choose one action: \n",
      " [1] Print \n",
      " [2] Classify a csv file with examples \n",
      " [3] Play Fourgame \n",
      " [4] Leave\n"
     ]
    }
   ],
   "source": [
    "from Dataset import Dataset\n",
    "from DecisionTree import DecisionTree\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "irisTree = DecisionTree(Dataset().readCSV('datasets/', 'iris', hasId=True))\n",
    "irisTreeBinning = DecisionTree(Dataset().readCSV('datasets/', 'iris', hasId=True, binCount=3), binning=True)\n",
    "connect4Tree = DecisionTree(Dataset().readCSV('datasets/', 'connect4_dataset', hasId=False, hasHeader=True))\n",
    "\n",
    "def chooseTree():\n",
    "    print(\"\\nEscolhe uma das árvores:\")\n",
    "    print(\"[1] Iris\")\n",
    "    print(\"[2] Iris com Binning\")\n",
    "    print(\"[3] Connect 4\")\n",
    "    option = input(\"Opção: \")\n",
    "\n",
    "    if option == '1':\n",
    "        return irisTree, 'datasets/', 'iris', True\n",
    "    elif option == '2':\n",
    "        return irisTreeBinning, 'datasets/', 'iris', True\n",
    "    elif option == '3':\n",
    "        return connect4Tree, 'datasets/', 'connect4_dataset', False\n",
    "    else:\n",
    "        print(\"Opção inválida.\")\n",
    "        return chooseTree()\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        print(\"\\nÁrvores de Decisão - Algoritmo ID3\")\n",
    "        print(\"1. Ver árvore\")\n",
    "        print(\"2. Classificar ficheiro CSV\")\n",
    "        print(\"3. Calcular precisão\")\n",
    "        print(\"4. Sair\")\n",
    "\n",
    "        op = input(\"Escolha a opção: \")\n",
    "\n",
    "        if op == '1':\n",
    "            tree, *_ = chooseTree()\n",
    "            print(\"\\nÁrvore:\")\n",
    "            tree.DFSPrint()\n",
    "\n",
    "        elif op == '2':\n",
    "            tree, path, file, hasId = chooseTree()\n",
    "            dataset = Dataset().readCSV(path, file, hasId=hasId, hasHeader=True)\n",
    "\n",
    "            print(\"\\nClassificações:\")\n",
    "            for i in range(dataset.lines):\n",
    "                predicted = tree.classifyExample(deepcopy(dataset), i)\n",
    "                print(f\"Linha {i + 1}: Classe prevista = {predicted}\")\n",
    "\n",
    "        elif op == '3':\n",
    "            tree, path, file, hasId = chooseTree()\n",
    "            dataset = Dataset().readCSV(path, file, hasId=hasId, hasHeader=True)\n",
    "            random.shuffle(dataset.array)\n",
    "\n",
    "            split_point = int(0.8 * dataset.lines)\n",
    "            train_data = Dataset(deepcopy(dataset.array[:split_point]), deepcopy(dataset.header))\n",
    "            test_data = Dataset(deepcopy(dataset.array[split_point:]), deepcopy(dataset.header))\n",
    "\n",
    "            tree = DecisionTree(train_data)\n",
    "\n",
    "            acertos = 0\n",
    "            total = test_data.lines\n",
    "\n",
    "            for i in range(total):\n",
    "                previsto = tree.classifyExample(deepcopy(test_data), i)\n",
    "                real = test_data.getValue(i, test_data.cols - 1)\n",
    "                if previsto == real:\n",
    "                    acertos += 1\n",
    "\n",
    "            print(f\"\\nPrecisão no conjunto de teste: {acertos}/{total} = {acertos / total * 100:.2f}%\")\n",
    "\n",
    "        elif op == '4':\n",
    "            print(\"Até à próxima!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Opção inválida.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect4 Dataset\n",
    "\n",
    "O dataset desenvolvido para o problema do Connect4 baseia-se em representar o estado atual do tabuleiro e prever a melhor próxima jogada, sendo esta determinada por meio de simulações com o algoritmo Monte Carlo Tree Search (MCTS).\n",
    "\n",
    "Devido à elevada complexidade do jogo com mais de 4,5 triliões de possíveis estados distintos optou-se por adicionar três atributos complementares: first_player, current_player e piece_count.\n",
    "\n",
    "first_player: indica quem iniciou a partida (X ou O),\n",
    "\n",
    "current_player: indica quem está prestes a jogar (quem realizará a jogada recomendada pelo MCTS),\n",
    "\n",
    "piece_count: representa o número total de peças já colocadas no tabuleiro até o momento.\n",
    "\n",
    "A introdução destes atributos teve como principal objetivo reduzir a incerteza associada à previsão da jogada ideal, ao contextualizar melhor o estado atual da partida. Por exemplo, dois tabuleiros idênticos podem representar situações completamente diferentes consoante quem iniciou o jogo ou quem joga no momento atual.\n",
    "\n",
    "No entanto, é importante salientar que a eficácia destes atributos está diretamente ligada à quantidade e à diversidade dos dados disponíveis:\n",
    "\n",
    "Em datasets pequenos, a presença destes atributos pode conduzir a overfitting, dado que o modelo pode aprender padrões esparsos ou específicos demais.\n",
    "\n",
    "Já em datasets maiores e mais balanceados, estes atributos oferecem uma melhor segmentação dos estados, permitindo à árvore de decisão realizar escolhas mais informadas e generalizáveis.\n",
    "\n",
    "Assim, o seu uso é justificado em cenários com volumes substanciais de dados e serve para atenuar o impacto do desbalanceamento natural num jogo com espaço de estados tão vasto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning e valores numéricos nos Datasets\n",
    "\n",
    "Valores numéricos levam a uma grande dimensão da árvore de decisão, no entanto são simples de ser agrupados em intervalos reduzindo o tamanho do dataset e consequentemente da árvore.\n",
    "\n",
    "Uma das técnicas utilizadas é conhecida por binning que consiste em agrupar um conjunto de dados numéricos em intervalos, reduzindo o tamanho mas com o risco de perda de informação no processo quanto maior for o tamanho dos intervalos.\n",
    "\n",
    "O objetivo então é encontrar o trade-off ideal de modo a reduzir o tamanho e manter a precisão o máximo possível.\n",
    "\n",
    "Este algoritmo foi então aplicado ao dataset do weather e da iris apresentando algumas imprecisões no caso da iris no teste de exemplos dados.\n",
    "\n",
    "Isto dá-se pelo fato de o mesmo intervalo ter precença de várias classes e sendo assim foi feita uma implementação que escolheria a de maior frequência reduzindo os erros.\n",
    "\n",
    "No entanto como no exemplo em baixo em que o intervalo tem 3 Iris-virginica e 1 Iris-versicolor, oque significa que em 4 valores 1 irá ter um resultado errado.\n",
    "\n",
    "![Teste](esquemas/intervalobinning.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Datasets\n",
    "\n",
    "Existem duas defenições de datasets os balanceados e não balanceados. \n",
    "\n",
    "Os balanceados são aqueles em que a frequência das classes é igual entre si e os não balanceados em que essa mesma frequência não o é.\n",
    "\n",
    "Datasets balanceados levam a árvores mais balanceadas e existem dois métodos para balanceamento dos datasets: Undersapling e Oversapling\n",
    "\n",
    "Undersapling consiste em reduzir o número de exemplos das classes com maior frequência até que fique balanceado\n",
    "Oversapling consiste em aumentar o número de exemplos das classes com menor frequência até que fique balanceado\n",
    "\n",
    "No nosso caso o dataset da iris está balanceado tendo 33% de cada classe que contêm (50/50/50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
